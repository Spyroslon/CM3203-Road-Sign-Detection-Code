{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageDetection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1GmCHHXszqloJaTLoijb--f2lP10PyYgY","authorship_tag":"ABX9TyMj60MPJ+YIRDZwxAjGLfR0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4E1sdgy4xi10","colab_type":"text"},"source":["# Image Detection with Tensorflow 1.x (GPU Enabled)\n"]},{"cell_type":"code","metadata":{"id":"_grGbmhPhlQ-","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AkNcNZBFx9aG","colab_type":"text"},"source":["# Enable GPU acceleration by navigating to \n","\n","> Edit > Notebook Settings > Choose \"GPU\" for hardware acceleration.\n","\n","Then run the cell below to make sure the GPU is setup. You should see 'Found GPU'"]},{"cell_type":"code","metadata":{"id":"KBnSc3Urx-r4","colab_type":"code","outputId":"362cccf2-c7d7-4642-88ec-8d9521bd8c50","executionInfo":{"status":"ok","timestamp":1588086544824,"user_tz":-180,"elapsed":36981,"user":{"displayName":"Spyros Londos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjatovqYzAkDrEC1B5hoN5KCdN0PCLTtsoPddToyQ=s64","userId":"00280497691462320490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4NirOetwyG5W","colab_type":"text"},"source":["# **Mount** your google drive my using **'Mount drive'** from the files section."]},{"cell_type":"markdown","metadata":{"id":"-dmjqugAzbM3","colab_type":"text"},"source":["Remember to change to the name of your folder. \n","\n","Setting the environment"]},{"cell_type":"code","metadata":{"id":"_QEIeLsqregF","colab_type":"code","outputId":"4d9050b0-07e5-44bd-9e07-39b0a9938730","executionInfo":{"status":"ok","timestamp":1589386943431,"user_tz":-180,"elapsed":671,"user":{"displayName":"Spyros Londos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjatovqYzAkDrEC1B5hoN5KCdN0PCLTtsoPddToyQ=s64","userId":"00280497691462320490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/RoadSignDetection/models/research/\n","import os\n","os.environ['PYTHONPATH'] += ':/content/drive/My Drive/RoadSignDetection/models/research/:/content/drive/My Drive/RoadSignDetection/models/research/slim'"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/RoadSignDetection/models/research\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MZvnTcgR9nV5","colab_type":"text"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"jAKhUrrZ9tXc","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import tensorflow as tf\n","import cv2\n","import time\n","from google.colab.patches import cv2_imshow\n","import glob\n","import csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpL3Qok_bfDE","colab_type":"code","colab":{}},"source":["# Import the object detection module.\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhJgWgd8sm5I","colab_type":"code","outputId":"d4a9dd62-e1cb-4fc8-c803-83df555a408d","executionInfo":{"status":"ok","timestamp":1589386949235,"user_tz":-180,"elapsed":670,"user":{"displayName":"Spyros Londos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjatovqYzAkDrEC1B5hoN5KCdN0PCLTtsoPddToyQ=s64","userId":"00280497691462320490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/content/drive/My Drive/RoadSignDetection/models/research/object_detection'"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/RoadSignDetection/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y9IE1q4k-B5m","colab_type":"text"},"source":["# Model Preparation"]},{"cell_type":"markdown","metadata":{"id":"mrob3JkP-O2D","colab_type":"text"},"source":["## Variables\n","\n","Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing the path."]},{"cell_type":"code","metadata":{"id":"awY7vA0U-FnR","colab_type":"code","colab":{}},"source":["MODEL_NAME = 'inference_Final_RCNN_13'\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFdNigZIBjxL","colab_type":"text"},"source":["# Load the Tensorflow model into memory."]},{"cell_type":"code","metadata":{"id":"qAUSVnWGBjAX","colab_type":"code","colab":{}},"source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","    sess = tf.Session(graph=detection_graph)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yPTF_s-Z-0To","colab_type":"text"},"source":["# Loading label map\n","Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `Speed limit (50km/h)`. Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"]},{"cell_type":"code","metadata":{"id":"nR8CFjzC-64s","colab_type":"code","colab":{}},"source":["PATH_TO_LABELS = 'training/label_map.pbtxt'\n","NUM_CLASSES = 13\n","\n","# Adding Labels and categories\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xOO3Y8vNCcOK","colab_type":"text"},"source":["# Main Object Detection Function"]},{"cell_type":"code","metadata":{"id":"LpJwHtHYDClr","colab_type":"code","colab":{}},"source":["def ObjectDetection(imagePath, actualCategory):\n","  \n","  image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","\n","  # Each box represents a part of the image where a particular object was detected.\n","  detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","\n","  # Each score represent how level of confidence for each of the objects.\n","  # Score is shown on the result image, together with the class label.\n","  detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","  detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","  num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n","\n","  image = cv2.imread(imagePath)\n","\n","  # Resize image with aspect ratio\n","  # With Min Dimensions:150 and Max Dimensions: 300\n","  resolutionDict = {}\n","  width = int(image.shape[1])\n","  height = int(image.shape[0])\n","  resolutionDict['width'] = width\n","  resolutionDict['height'] = height\n","  aspectRatio = height / width\n","  minResol = min(resolutionDict.items(), key=lambda x: x[1])\n","  maxResol = max(resolutionDict.items(), key=lambda x: x[1])\n","\n","  # Resizing to 150 minimum dimenion\n","  # Whilst having a cap for the other dimension for 300\n","  if minResol[1] < 150:\n","    if minResol[0] == 'width':\n","      width = 150\n","      height = width * aspectRatio\n","      if height > 300:\n","        height = 300\n","    elif minResol[0] == 'height':\n","      height = 150\n","      width = height / aspectRatio\n","      if width > 300:\n","        width = 300\n","  \n","  # Resizing to 300 maximum dimenion\n","  # Whilst having a cap for the other dimension for 150\n","  elif maxResol[1] > 300:\n","    if maxResol[0] == 'width':\n","      width = 300\n","      height = width * aspectRatio\n","      if height < 150:\n","        height = 150\n","    if maxResol[0] == 'height':\n","      height = 300\n","      width = height / aspectRatio\n","      if width < 150:\n","        width = 150\n","  \n","  image = cv2.resize(image, (int(width), int(height)))\n","\n","  # Resize image without aspect ratio\n","  # width = 150\n","  # height = 150\n","  # image = cv2.resize(image, (int(width), int(height)))\n","\n","  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","  image_np_expanded = np.expand_dims(image, axis=0)\n","\n","  # Actual detection.\n","  (boxes, scores, classes, num) = sess.run(\n","      [detection_boxes, detection_scores, detection_classes, num_detections],\n","      feed_dict={image_tensor: image_np_expanded})\n","  \n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image,\n","      np.squeeze(boxes),\n","      np.squeeze(classes).astype(np.int32),\n","      np.squeeze(scores),\n","      category_index,\n","      use_normalized_coordinates=True, \n","      line_thickness=3,\n","      min_score_thresh=.5)\n","\n","  # Provides output of the category with higest score\n","  predictedClass = [category_index.get(i).get('name') for i in classes[0]][0]\n","  if predictedClass == actualCategory:\n","    cv2_imshow(image)\n","    return 1\n","  else:\n","    cv2_imshow(image)\n","    return 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Im2O7ycLDQwa","colab_type":"text"},"source":["# Testing Images in the 'test_images' folder and getting model the performance metrics"]},{"cell_type":"code","metadata":{"id":"6It2qhZLmeOL","colab_type":"code","outputId":"aca75089-0a3e-4d21-d2c7-b0cd91a0436a","executionInfo":{"status":"ok","timestamp":1589377781215,"user_tz":-180,"elapsed":1149,"user":{"displayName":"Spyros Londos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjatovqYzAkDrEC1B5hoN5KCdN0PCLTtsoPddToyQ=s64","userId":"00280497691462320490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/content/drive/My Drive/RoadSignDetection/models/research/object_detection'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/RoadSignDetection/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IHELiqSJDvGA","colab_type":"code","outputId":"14845885-2ff9-4396-a732-7df7ca0c6617","executionInfo":{"status":"ok","timestamp":1589387196030,"user_tz":-180,"elapsed":18006,"user":{"displayName":"Spyros Londos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjatovqYzAkDrEC1B5hoN5KCdN0PCLTtsoPddToyQ=s64","userId":"00280497691462320490"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uyzYXkX_i428XxYQcSckbAHqxv9kEill"}},"source":["testImagesInfo = {}\n","with open('test_labels.csv', 'r') as currentfile:\n","  reader = csv.reader(currentfile)\n","  next(reader)\n","  for row in reader:\n","    testImagesInfo[row[0]] = row[3]\n","\n","os.chdir('test_images')\n","TEST_IMAGE_PATHS = glob.glob('*.jpg')\n","TEST_IMAGE_PATHS.extend(glob.glob('*.png'))\n","correctDetections = 0\n","numImages = 0\n","\n","startTime = time.time()\n","\n","for imagePath in TEST_IMAGE_PATHS:\n","  numImages += 1\n","  correctDetections += ObjectDetection(imagePath, testImagesInfo.get(imagePath))\n","\n","endTime = time.time()\n","\n","print('FPS: ', round(numImages/(endTime - startTime),2))\n","print('Speed(ms): ',  round(((endTime - startTime)/numImages)*1000,2))\n","print('Accuracy: ', round(correctDetections/numImages * 100,2),'%')\n","os.chdir(\"..\")"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}